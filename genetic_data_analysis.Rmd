---
title: "Genetic background lipids"
author: 
- "DeniseSl22"
date: "01/08/2022"
output: html_notebook
---

In order to establish the potential genetic relevance of a certain modeling species in lipid metabolism, we take these steps:
1. First, we obtain human genes from three databases (Gene Ontology, Reactome, and WikiPathways) together to establish a list of relevant proteins in lipid metabolism.
2. Second, we compare these three databases together, while grouping on EC-nomenclature/LIPID MAPS ontology.
3. Thirds, we use the overlapping genes to compare against other modeling species (mouse, zebrafish, yeast, worm), to represent which genes can be found in which species, and might make a suitable modeling organism.

## 1. Relevant proteins from Databases: 

From the Quick-GO website (https://www.ebi.ac.uk/QuickGO/), we downloaded data based on the following criteria:
I. Taxon: 9606 (Homo sapiens, human).
II. Gene product type: Proteins, Reviewed (Swiss-Prot), all settings for Proteomes.
III. GO terms: lipid metabolic process (GO:0006629).

Data was downloaded on: 1st of August, with 5199 annotations, as a TSV file.
```{r}
##GO terms
go_terms <- read.delim(file = "QuickGO-annotations-1659356807403-20220801.tsv", header = TRUE, sep = '\t')
go_terms_unique <- unique(go_terms$SYMBOL)

```

```{r}
##Reactome
if(!"SPARQL" %in% installed.packages()){
  install.packages("SPARQL")
}
library(SPARQL)
##Connect to Endpoint WikiPathways
endpointwp <- "https://sparql.wikipathways.org/sparql"

## 1. Query metadata:
queryMetadata <-
"SELECT DISTINCT ?dataset (str(?titleLit) as ?title) ?date ?license 
WHERE {
   ?dataset a void:Dataset ;
   dcterms:title ?titleLit ;
   dcterms:license ?license ;
   pav:createdOn ?date .
 }"
 #below code should be performed first to handle the ssl certificate error
options(RCurlOptions = list(cainfo = paste0( tempdir() , "/cacert.pem" ), ssl.verifypeer = FALSE))
resultsMetadata <- SPARQL(endpointwp,queryMetadata,curl_args=list(useragent=R.version.string))
showresultsMetadata <- resultsMetadata$results
remove(queryMetadata, resultsMetadata)

## 2. Query Reactome lipid PWs, through HGNC symbols:
queryReactome <-
"PREFIX cur:            <http://vocabularies.wikipathways.org/wp#Curation:> #to differentiate between Reactome and WP PWs.

select distinct (str(?wpid) as ?pathway) (count(distinct ?lipidID) AS ?LipidsInPWs) (fn:substring(?hgncId,37) as ?HGNC) 
where {
  ?pathwayRes a wp:Pathway ;                   #Define what is a pathway
              wp:organismName 'Homo sapiens' ; #Filter pathways on species Human
              dcterms:identifier ?wpid ;       #Obtain identifier of pathway
              wp:ontologyTag cur:Reactome_Approved .  #Reactome: Reactome_Approved . WP: Curation:AnalysisCollection
  
  ?metabolite wp:bdbLipidMaps ?lipidID ;       #Find the LIPID MAPS identifier for a certain metabolite
              dcterms:isPartOf ?pathwayRes .   #Connect lipid to PW 
    
  
  ?protein wp:bdbHgncSymbol ?hgncId ;          #Find proteins based on HGNC symbol
           dcterms:isPartOf ?pathwayRes .      #Connect protein to PW
}
ORDER BY DESC(?LipidsInPWs)
"
##Execute query:
resultsReactome <- SPARQL(endpointwp,queryReactome,curl_args=list(useragent=R.version.string))
showresultsReactome <- resultsReactome$results
remove(queryReactome, resultsReactome)

##Only retain PWs with 4 or more lipids involved, and create string of unieuq HGNC symbols.
reactome_terms <- showresultsReactome[showresultsReactome$LipidsInPWs>=4, ]
reactome_terms_unique <- unique(reactome_terms$HGNC)
```

```{r}
##WikiPathways
## 3. Query WikiPathways lipid PWs, through HGNC symbols:
queryWikiPathways <-
"PREFIX cur:            <http://vocabularies.wikipathways.org/wp#Curation:> #to differentiate between Reactome and WP PWs.

select distinct (str(?wpid) as ?pathway) (count(distinct ?lipidID) AS ?LipidsInPWs) (fn:substring(?hgncId,37) as ?HGNC) 
where {
  ?pathwayRes a wp:Pathway ;                   #Define what is a pathway
              wp:organismName 'Homo sapiens' ; #Filter pathways on species Human
              dcterms:identifier ?wpid ;       #Obtain identifier of pathway
              wp:ontologyTag cur:AnalysisCollection .  #Reactome: Reactome_Approved . WP: Curation:AnalysisCollection
  
  ?metabolite wp:bdbLipidMaps ?lipidID ;       #Find the LIPID MAPS identifier for a certain metabolite
              dcterms:isPartOf ?pathwayRes .   #Connect lipid to PW 
    
  
  ?protein wp:bdbHgncSymbol ?hgncId ;          #Find proteins based on HGNC symbol
           dcterms:isPartOf ?pathwayRes .      #Connect protein to PW
}
ORDER BY DESC(?LipidsInPWs)
"
##Execute query:
resultsWikiPathways <- SPARQL(endpointwp,queryWikiPathways,curl_args=list(useragent=R.version.string))
showresultsWikiPathways <- resultsWikiPathways$results
remove(queryWikiPathways, resultsWikiPathways)

##Only retain PWs with 4 or more lipids involved, and create string of unieuq HGNC symbols.
wikipathways_terms <- showresultsWikiPathways[showresultsWikiPathways$LipidsInPWs>=4, ]
wikipathways_terms_unique <- unique(wikipathways_terms$HGNC)

```

## 2. Compare databases

From the HGNC biomart webiste (http://biomart.genenames.org/), we downloaded data based on the following criteria:
I. Start search by selecting "gene"
II. Status: Approved
III. Attributes: HGNC ID, Status, Approved Symbol, Approved Name.
IV. Protein resources: Enzyme (EC) ID.

HGNC to EC-code data was downloaded on: 1st of August, with 43295 lines, as a TSV file.
```{r}
# Read the HGNC to EC-code file:
EC_terms <- read.delim(file = "HGNC_biomart.txt", header = TRUE, sep = '\t', na.strings = "")
# Add 'unclassified' iso 'NA' values
EC_terms <- replace(EC_terms, is.na(EC_terms), "unclassified")
# Keep only relevant columns:
EC_terms_HGNC <- EC_terms[, c("Approved.symbol","Enzyme..EC..ID")]

```

Link the EC codes to HGNC symbols for each database, and combine the data in one dataframe:
```{r}
## Find HGNC symbols that are not recognized, for data curation:
EC_terms_GO_not <-  setdiff(go_terms_unique, EC_terms_HGNC$Approved.symbol) 
EC_terms_Reactome_not <-  setdiff(reactome_terms_unique, EC_terms_HGNC$Approved.symbol) 
EC_terms_WikiPathways_not <-  setdiff(wikipathways_terms_unique, EC_terms_HGNC$Approved.symbol) 

##TODO: Map these HGNC IDs to automatically updated to new entries through BridgeDb using secondary to primary mapping.

## Find these HGNC symbols in the 'multi-symbol-checker' (https://www.genenames.org/tools/multi-symbol-checker/), 
## Manually remove the first row 'sep=', otherwise the file cannot be read in properly
## and read in CSV download:
HGNC_mapping_terms <- read.csv(file = "hgnc-symbol-check.csv", header = TRUE, na.strings = "")

#Create new array to compare changes later:
go_terms_new <- go_terms_unique
reactome_terms_new <- reactome_terms_unique
wikipathways_terms_new <- wikipathways_terms_unique

##Replace the symbols if 'match.type' == 	'Previous symbol', otherwise remove the entry
#GO
for (i in 1:nrow(HGNC_mapping_terms)) {
    if (HGNC_mapping_terms$Match.type[i] == 'Previous symbol') {
    #Update entry
    go_terms_new <- replace(go_terms_new, go_terms_new == HGNC_mapping_terms$Input[i], HGNC_mapping_terms$Approved.symbol[i])
    }else if(HGNC_mapping_terms$Match.type[i] != 'Previous symbol'){
    #Remove entry
    go_terms_new <-  replace(go_terms_new, go_terms_new == HGNC_mapping_terms$Input[i], 'remove')
    go_terms_new <- go_terms_new[!go_terms_new %in% 'remove']
    }
}

#Reactome
for (i in 1:nrow(HGNC_mapping_terms)) {
    if (HGNC_mapping_terms$Match.type[i] == 'Previous symbol') {
    #Update entry
    reactome_terms_new <- replace(reactome_terms_new, reactome_terms_new == HGNC_mapping_terms$Input[i], HGNC_mapping_terms$Approved.symbol[i])
    }else if(HGNC_mapping_terms$Match.type[i] != 'Previous symbol'){
    #Remove entry
    reactome_terms_new <- replace(reactome_terms_new, reactome_terms_new == HGNC_mapping_terms$Input[i], 'remove')
    reactome_terms_new <- reactome_terms_new[!reactome_terms_new %in% 'remove']
    }
}

#WikiPathways
for (i in 1:nrow(HGNC_mapping_terms)) {
    if (HGNC_mapping_terms$Match.type[i] == 'Previous symbol') {
    #Update entry
    wikipathways_terms_new <- replace(wikipathways_terms_new, wikipathways_terms_new == HGNC_mapping_terms$Input[i], HGNC_mapping_terms$Approved.symbol[i])
    }else if(HGNC_mapping_terms$Match.type[i] != 'Previous symbol'){
    #Remove entry
    wikipathways_terms_new <- replace(wikipathways_terms_new, wikipathways_terms_new == HGNC_mapping_terms$Input[i], 'remove')
    wikipathways_terms_new <- wikipathways_terms_new[!wikipathways_terms_new %in% 'remove']
    }
}

```

Visualize overlap in Venn diagram:
```{r}
if(!"VennDiagram" %in% installed.packages()){install.packages("VennDiagram")}
if(!"RColorBrewer" %in% installed.packages()){install.packages("RColorBrewer")}
# Load library
library(VennDiagram)
# Prepare a palette of 3 colors with R colorbrewer:
library(RColorBrewer)
myCol <- brewer.pal(3, "Pastel2")
##Ignore log messages:
futile.logger::flog.threshold(futile.logger::ERROR, name = "VennDiagramLogger")

# Chart
venn.diagram(
        x = list(go_terms_new, reactome_terms_new, wikipathways_terms_new),
        category.names = c("Gene Ontology" , "Reactome" , "WikiPathways"),
        filename = 'Overlap_GO_Re_WP.png',
        output=TRUE,
        
        # Output features
        imagetype="png" ,
        height = 650 , 
        width = 700 , 
        resolution = 300,
        compression = "lzw",
        
        # Circles
        lwd = 2,
        lty = 'blank',
        fill = myCol,
        
        # Numbers
        cex = .6,
        fontface = "bold",
        fontfamily = "sans",
        
        # Set names
        cat.cex = 0.6,
        cat.fontface = "bold",
        cat.default.pos = "outer",
        cat.pos = c(-27, 27, 135),
        cat.dist = c(0.055, 0.055, 0.085),
        cat.fontfamily = "sans",
        rotation = 1
)
```

Connect data to EC codes:
```{r}
if(!"dplyr" %in% installed.packages()){
  install.packages("dplyr")
}
library(dplyr)

##Link data from three databases to EC-codes:
EC_terms_GO <-  EC_terms_HGNC[EC_terms_HGNC$Approved.symbol %in% go_terms_new, ]
EC_terms_Reactome <-  EC_terms_HGNC[EC_terms_HGNC$Approved.symbol %in% reactome_terms_new, ]
EC_terms_WikiPathways <-  EC_terms_HGNC[EC_terms_HGNC$Approved.symbol %in% wikipathways_terms_new, ]

##Combine data
combined_data12 <- merge(x = EC_terms_GO, y = EC_terms_Reactome, by = "Approved.symbol", all.x = TRUE, all.y=TRUE, sort = TRUE)
combined_data_all <- merge(x = combined_data12 , y = EC_terms_WikiPathways, by = "Approved.symbol", all.x = TRUE, all.y=TRUE, sort = TRUE)

#Rename the columns:
colnames(combined_data_all) <- c("HGNC", "GO", "Reactome", "WikiPathways")
```


Convert data to adjacency matrix:
```{r}
#create data backup:
combined_data_noDuplicates <- combined_data_all
# Remove duplicate HGNC terms, since several HGNC terms have multiple EC-codes (e.g. AADAT has EC-code 2.6.1.7 and 2.6.1.39):
combined_data_noDuplicates <- combined_data_noDuplicates %>% distinct(combined_data_noDuplicates$HGNC , .keep_all = TRUE)
#Remove last column added by distinct method
combined_data_noDuplicates <- subset(combined_data_noDuplicates, select = -c(5) )
##Count entries for each column, to see if this matches with new terms and we're not forgetting some proteins along the way!
length(go_terms_new) == sum(!is.na(combined_data_noDuplicates$GO))
length(reactome_terms_new) == sum(!is.na(combined_data_noDuplicates$Reactome))
length(wikipathways_terms_new) == sum(!is.na(combined_data_noDuplicates$WikiPathways))

# Sort the columns based on HGNC symbol:
combined_data_noDuplicates <- combined_data_noDuplicates[order(combined_data_noDuplicates$HGNC),]

##Labels for EC classes:
# EC 1: Oxidoreductases
# EC 2: Transferases
# EC 3: Hydrolases
# EC 4: Lyases
# EC 5: Isomerases
# EC 6: Ligases
# EC 7: Translocases

##Unify the EC entries to their class name:
# GO
combined_data_noDuplicates <- combined_data_noDuplicates%>%mutate(GO_class = case_when(
  startsWith(combined_data_noDuplicates$GO, '1.') ~ 'GO_1',
  startsWith(combined_data_noDuplicates$GO, '2.') ~ 'GO_2',
  startsWith(combined_data_noDuplicates$GO, '3.') ~ 'GO_3',
  startsWith(combined_data_noDuplicates$GO, '4.') ~ 'GO_4',
  startsWith(combined_data_noDuplicates$GO, '5.') ~ 'GO_5',
  startsWith(combined_data_noDuplicates$GO, '6.') ~ 'GO_6',
  startsWith(combined_data_noDuplicates$GO, '7.') ~ 'GO_7',
  is.na(combined_data_noDuplicates$GO) ~ combined_data_noDuplicates$GO, 
  TRUE ~ 'GO_U'
))

# Reactome (Re)
combined_data_noDuplicates <- combined_data_noDuplicates%>%mutate(Re_class = case_when(
  startsWith(combined_data_noDuplicates$Reactome, '1.') ~ 'Re_1',
  startsWith(combined_data_noDuplicates$Reactome, '2.') ~ 'Re_2',
  startsWith(combined_data_noDuplicates$Reactome, '3.') ~ 'Re_3',
  startsWith(combined_data_noDuplicates$Reactome, '4.') ~ 'Re_4',
  startsWith(combined_data_noDuplicates$Reactome, '5.') ~ 'Re_5',
  startsWith(combined_data_noDuplicates$Reactome, '6.') ~ 'Re_6',
  startsWith(combined_data_noDuplicates$Reactome, '7.') ~ 'Re_7',
  is.na(combined_data_noDuplicates$Reactome) ~ combined_data_noDuplicates$Reactome, 
  TRUE ~ 'Re_U'
))

# WikiPathways (WP)
combined_data_noDuplicates <- combined_data_noDuplicates%>%mutate(WP_class = case_when(
  startsWith(combined_data_noDuplicates$WikiPathways, '1.') ~ 'WP_1',
  startsWith(combined_data_noDuplicates$WikiPathways, '2.') ~ 'WP_2',
  startsWith(combined_data_noDuplicates$WikiPathways, '3.') ~ 'WP_3',
  startsWith(combined_data_noDuplicates$WikiPathways, '4.') ~ 'WP_4',
  startsWith(combined_data_noDuplicates$WikiPathways, '5.') ~ 'WP_5',
  startsWith(combined_data_noDuplicates$WikiPathways, '6.') ~ 'WP_6',
  startsWith(combined_data_noDuplicates$WikiPathways, '7.') ~ 'WP_7',
  is.na(combined_data_noDuplicates$WikiPathways) ~ combined_data_noDuplicates$WikiPathways, 
  TRUE ~ 'WP_U'
))

if(!"reshape2" %in% installed.packages()){
  install.packages("reshape2")
}
if(!"reshape" %in% installed.packages()){
  install.packages("reshape")
}
library(reshape2) 
library(reshape) 

#Keep only relevant columns
GO_Re <- combined_data_noDuplicates[,c(5,6)]
GO_WP <- combined_data_noDuplicates[,c(5,7)]
WP_Re <- combined_data_noDuplicates[,c(6,7)]

#Melt data to obtain an edge list
melt_data_GO_Re <- na.omit(melt(GO_Re, id = c('GO_class'))) 
melt_data_GO_WP <- na.omit(melt(GO_WP, id = c('GO_class'))) 
melt_data_WP_Re <- na.omit(melt(WP_Re, id = c('Re_class'))) 

#Merge data back together
lst <- mget(ls(pattern='^melt_data_'))
list2env(lapply(lst,`[`,-2), envir=.GlobalEnv)
names(melt_data_WP_Re)[1] <- names(melt_data_GO_Re)[1]
merged_comparison <-  do.call("rbind", list(melt_data_GO_Re, melt_data_GO_WP, melt_data_WP_Re))
names(merged_comparison) <- c('Database1','DataBase2')

#Filter out the Unclassified interactions, since these clutter the visualization:
merged_comparison <- dplyr::filter(merged_comparison, !grepl('U', Database1))

##Calculate occurrence (edge weight)
#if(!"plyr" %in% installed.packages()){
#  install.packages("plyr")
#}
#library(plyr)
#merged_comparison_weight <- ddply(merged_comparison, .(Database1,DataBase2), nrow)
#names(merged_comparison_weight)[3] <- 'weight'
##Count unique entries in dataset before constructing the matrix size:
#unique_edges <-  merged_comparison_weight %>% 
#  select(Database1, DataBase2) %>% 
#  t %>% c %>% unique

##Use the igraph library to calculate the adjacency matrix:
if(!"igraph" %in% installed.packages()){
  install.packages("igraph")
}
library(igraph)
adjacencyData <- as.matrix(get.adjacency(graph.data.frame(merged_comparison)))

##Create a chord diagram to visualize overlap:
# Charge the circlize library
if(!"circlize" %in% installed.packages()){
  install.packages("circlize")
}
library(circlize)
 
# Make the circular plot
chordDiagram(adjacencyData, transparency = 0.5)

##TODO: update visualization, so labels are more readable.

```

